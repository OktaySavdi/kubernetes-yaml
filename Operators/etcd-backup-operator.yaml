# ServiceAccount for the operator
apiVersion: v1
kind: ServiceAccount
metadata:
  name: etcd-backup-operator
  namespace: gt-operators
---
# ClusterRole: Permissions to manage etcd-backup resources
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: etcd-backup-operator-role
rules:
  - apiGroups: [""]
    resources: ["namespaces"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
  - apiGroups: [""]
    resources: ["serviceaccounts"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
  - apiGroups: ["batch"]
    resources: ["cronjobs"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
  - apiGroups: ["batch"]
    resources: ["jobs"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["clusterroles", "clusterrolebindings"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: etcd-backup-operator-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: etcd-backup-operator-role
subjects:
- kind: ServiceAccount
  name: etcd-backup-operator
  namespace: gt-operators
---
# ConfigMap containing the etcd-backup manifest
apiVersion: v1
kind: ConfigMap
metadata:
  name: etcd-backup-manifest
  namespace: gt-operators
data:
  manifest.yaml: |
    ---
    # ServiceAccount: Identity for the backup pods
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: etcd-backup-sa
      namespace: gt-operators
    ---
    # ClusterRole: Permissions needed for the backup process
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: etcd-backup-role
    rules:
      # Allow reading node information
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get", "list"]
      # Allow reading pod information
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["get", "list"]
      # Allow reading pod logs
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get"]
    ---
    # ClusterRoleBinding: Grant permissions to the ServiceAccount
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: etcd-backup-rolebinding
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: etcd-backup-role
    subjects:
      - kind: ServiceAccount
        name: etcd-backup-sa
        namespace: gt-operators
    ---
    # ConfigMap: Contains the backup script that runs in the pod
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: etcd-backup-script
      namespace: gt-operators
    data:
      backup.sh: |
        #!/bin/sh
        set -e  # Exit immediately if any command fails
        
        # ===== INSTALL REQUIRED TOOLS =====
        # Check and install curl (needed for Teams notifications)
        if ! command -v curl >/dev/null 2>&1; then
            echo "Installing curl..."
            apk add --no-cache curl
        fi
        
        # Check and install kubectl (needed for cluster name detection)
        if ! command -v kubectl >/dev/null 2>&1; then
            echo "Installing kubectl..."
            apk add --no-cache curl
            # Get the latest stable kubectl version
            KUBECTL_VERSION=$(curl -L -s https://dl.k8s.io/release/stable.txt)
            # Download kubectl binary
            curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
            chmod +x kubectl
            mv kubectl /usr/local/bin/
        fi
        
        # Check and install etcdctl (needed for etcd backup)
        if ! command -v etcdctl >/dev/null 2>&1; then
            echo "Installing etcdctl..."
            ETCD_VER=v3.5.15  # etcd client version
            DOWNLOAD_URL=https://github.com/etcd-io/etcd/releases/download
            # Download etcd release package
            wget -q ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -O /tmp/etcd.tar.gz
            # Extract the archive
            tar xzf /tmp/etcd.tar.gz -C /tmp
            # Move only etcdctl binary to /usr/local/bin
            mv /tmp/etcd-${ETCD_VER}-linux-amd64/etcdctl /usr/local/bin/
            # Clean up temporary files
            rm -rf /tmp/etcd*
        fi
        
        # ===== CONFIGURATION =====
        BACKUP_DIR="/opt/backup"  # Directory where backups are stored
        MAX_BACKUPS=10  # Maximum number of backups to keep per node
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)  # Timestamp format: YYYYMMDD-HHMMSS
        NODE_NAME=$(hostname)  # Get current node hostname (unique per control plane node)
        BACKUP_FILE="etcd-backup-${NODE_NAME}-${TIMESTAMP}.tar.gz"  # Backup filename with node name
        
        # Auto-detect cluster name from kubectl context
        if [ -z "${CLUSTER_NAME}" ] || [ "${CLUSTER_NAME}" = "openshift-cluster" ]; then
            # Try to get cluster name from kubectl config
            CLUSTER_NAME=$(kubectl config current-context 2>/dev/null || echo "unknown-cluster")
        fi
        
        echo "Starting etcd backup at $(date)"
        
        # Create backup directory if it doesn't exist
        mkdir -p "${BACKUP_DIR}"
        
        # ===== TEAMS NOTIFICATION FUNCTION =====
        # Function to send notification to Microsoft Teams webhook
        send_notification() {
            local status=$1    # Status: SUCCESS or FAILED
            local message=$2   # Detailed message to send
            
            # Only send notification if webhook URL is configured
            if [ -n "${TEAMS_WEBHOOK_URL}" ]; then
                # Set color and emoji based on status
                local color="FF0000"  # Red for failed
                local emoji="‚ùå"
                
                if [ "${status}" = "SUCCESS" ]; then
                    color="00FF00"  # Green for success
                    emoji="‚úÖ"
                fi
                
                # Send Teams message card using webhook
                curl -X POST -H 'Content-Type: application/json' \
                    -d "{
                        \"@type\": \"MessageCard\",
                        \"@context\": \"https://schema.org/extensions\",
                        \"summary\": \"ETCD Backup ${status}\",
                        \"themeColor\": \"${color}\",
                        \"title\": \"${emoji} ETCD Backup ${status}\",
                        \"sections\": [{
                            \"activityTitle\": \"Cluster: ${CLUSTER_NAME:-unknown}\",
                            \"facts\": [
                                {\"name\": \"Status\", \"value\": \"${status}\"},
                                {\"name\": \"Node\", \"value\": \"${NODE_NAME:-unknown}\"},
                                {\"name\": \"Message\", \"value\": \"${message}\"},
                                {\"name\": \"Time\", \"value\": \"$(date)\"},
                                {\"name\": \"Namespace\", \"value\": \"gt-operators\"}
                            ]
                        }]
                    }" \
                    "${TEAMS_WEBHOOK_URL}" || echo "Failed to send Teams notification"
            fi
            
            # Also log to stdout for pod logs
            echo "${status}: ${message}"
        }
        
        # ===== ERROR HANDLING =====
        # Trap: Send notification and exit if any error occurs
        trap 'send_notification "FAILED" "Backup script encountered an error at line $LINENO. Check pod logs for details: kubectl logs -n gt-operators <pod-name>"' ERR
        
        # ===== DETECT CLUSTER TYPE AND PERFORM BACKUP =====
        # Check if running on OpenShift (has different etcd backup method)
        if [ -d "/host/etc/kubernetes/static-pod-resources/etcd-certs" ]; then
            echo "Detected OpenShift cluster"
            
            # OpenShift: Get running etcd pod name
            ETCD_POD=$(oc get pods -n openshift-etcd -l app=etcd --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}')
            
            # Verify etcd pod was found
            if [ -z "${ETCD_POD}" ]; then
                send_notification "FAILED" "No running etcd pod found in openshift-etcd namespace. Possible causes: 1) etcd pods are not running, 2) etcd pods don't have label app=etcd, 3) All etcd pods are in non-Running state"
                exit 1
            fi
            
            echo "Backing up etcd from pod: ${ETCD_POD}"
            
            # Execute OpenShift cluster backup script inside etcd pod
            oc exec -n openshift-etcd "${ETCD_POD}" -- /bin/sh -c \
                "/usr/local/bin/cluster-backup.sh /home/core/assets/backup" || {
                send_notification "FAILED" "cluster-backup.sh execution failed in pod ${ETCD_POD}. Possible causes: 1) cluster-backup.sh script not found, 2) Insufficient permissions, 3) Disk space issues on etcd pod"
                exit 1
            }
            
            # Copy backup files from etcd pod to backup directory
            oc cp -n openshift-etcd "${ETCD_POD}:/home/core/assets/backup/" "${BACKUP_DIR}/temp-backup-${TIMESTAMP}/" || {
                send_notification "FAILED" "Failed to copy backup from etcd pod ${ETCD_POD}. Possible causes: 1) Backup files not created, 2) Permission denied on target directory, 3) Network issues"
                exit 1
            }
            
            # Create compressed archive from copied files
            cd "${BACKUP_DIR}"
            tar -czf "${BACKUP_FILE}" -C "temp-backup-${TIMESTAMP}" . || {
                send_notification "FAILED" "Failed to create backup archive. Possible causes: 1) Insufficient disk space in ${BACKUP_DIR}, 2) tar command failed, 3) Permission denied"
                exit 1
            }
            
            # Cleanup temporary directory
            rm -rf "temp-backup-${TIMESTAMP}"
            
        else
            # Standard Kubernetes (TKG, kubeadm, etc.)
            echo "Detected standard Kubernetes cluster"
            
            # Verify etcd certificates are available
            if [ ! -f "/etc/kubernetes/pki/etcd/ca.crt" ]; then
                send_notification "FAILED" "etcd CA certificate not found at /etc/kubernetes/pki/etcd/ca.crt. Possible causes: 1) Wrong certificate path for this cluster, 2) Certificates not mounted correctly, 3) etcd using different certificate location"
                exit 1
            fi
            
            # Create etcd snapshot using etcdctl
            ETCDCTL_API=3 etcdctl snapshot save "${BACKUP_DIR}/${BACKUP_FILE}" \
                --endpoints=https://127.0.0.1:2379 \
                --cacert=/etc/kubernetes/pki/etcd/ca.crt \
                --cert=/etc/kubernetes/pki/etcd/server.crt \
                --key=/etc/kubernetes/pki/etcd/server.key || {
                send_notification "FAILED" "etcdctl snapshot failed on node ${NODE_NAME}. Possible causes: 1) etcd not listening on 127.0.0.1:2379, 2) Certificate authentication failed, 3) etcd not healthy, 4) Insufficient disk space in ${BACKUP_DIR}, 5) Network connectivity issues"
                exit 1
            }
        fi
        
        # ===== VERIFY BACKUP =====
        # Check that backup file was created successfully
        if [ ! -f "${BACKUP_DIR}/${BACKUP_FILE}" ]; then
            send_notification "FAILED" "Backup file was not created at ${BACKUP_DIR}/${BACKUP_FILE}. Possible causes: 1) Backup command failed silently, 2) Permission issues, 3) Disk full"
            exit 1
        fi
        
        # Get backup file size in human-readable format
        BACKUP_SIZE=$(du -h "${BACKUP_DIR}/${BACKUP_FILE}" | cut -f1)
        echo "Backup created: ${BACKUP_FILE} (Size: ${BACKUP_SIZE})"
        
        # ===== CLEANUP OLD BACKUPS =====
        # Keep only the last MAX_BACKUPS backups for this specific node
        echo "Cleaning up old backups (keeping last ${MAX_BACKUPS})..."
        cd "${BACKUP_DIR}"
        # List backups for this node, sorted by time, delete old ones
        # tail -n +$((MAX_BACKUPS + 1)): Skip first MAX_BACKUPS files, delete the rest
        ls -t etcd-backup-${NODE_NAME}-*.tar.gz 2>/dev/null | tail -n +$((MAX_BACKUPS + 1)) | xargs -r rm -f
        
        # Count remaining backups for reporting
        REMAINING_BACKUPS=$(ls -1 etcd-backup-${NODE_NAME}-*.tar.gz 2>/dev/null | wc -l)  # This node's backups
        TOTAL_ALL_BACKUPS=$(ls -1 etcd-backup-*.tar.gz 2>/dev/null | wc -l)  # All nodes' backups
        echo "Backup completed successfully. Node backups: ${REMAINING_BACKUPS}, Total all nodes: ${TOTAL_ALL_BACKUPS}"
        
        # ===== SUCCESS NOTIFICATION =====
        # Success notification is DISABLED to avoid noise (only logs to stdout)
        # Uncomment the line below to enable Teams notifications on success
        # send_notification "SUCCESS" "Backup completed. File: ${BACKUP_FILE}, Size: ${BACKUP_SIZE}, Node backups: ${REMAINING_BACKUPS}, Total: ${TOTAL_ALL_BACKUPS}"
        echo "SUCCESS: Backup completed. File: ${BACKUP_FILE}, Size: ${BACKUP_SIZE}, Node backups: ${REMAINING_BACKUPS}, Total: ${TOTAL_ALL_BACKUPS}"
        
        exit 0
    ---
    # CronJob: Scheduled backup job configuration
    apiVersion: batch/v1
    kind: CronJob
    metadata:
      name: etcd-backup
      namespace: gt-operators
    spec:
      # Schedule: Run every night at 2 AM (cron format: minute hour day month weekday)
      schedule: "0 2 * * *"
      # Keep last 3 successful and 3 failed jobs for debugging
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 3
      # Allow concurrent jobs to run on different control plane nodes
      concurrencyPolicy: Allow
      jobTemplate:
        spec:
          # Create one pod per control plane node (3 nodes = 3 pods)
          completions: 3    # Total number of pods to run
          parallelism: 3    # Number of pods to run simultaneously
          # Retry once on failure
          backoffLimit: 1
          template:
            metadata:
              labels:
                app: etcd-backup  # Label used for pod identification
            spec:
              serviceAccountName: etcd-backup-sa  # Use the ServiceAccount for RBAC
              # ===== POD SCHEDULING CONFIGURATION =====
              # Affinity rules: Ensure one pod runs on each control plane node
              affinity:
                # Pod Anti-Affinity: Prevent multiple backup pods on same node
                podAntiAffinity:
                  requiredDuringSchedulingIgnoredDuringExecution:
                  - labelSelector:
                      matchExpressions:
                      - key: app
                        operator: In
                        values:
                        - etcd-backup
                    topologyKey: "kubernetes.io/hostname"  # Distribute by hostname
                # Node Affinity: Only run on control plane nodes
                nodeAffinity:
                  requiredDuringSchedulingIgnoredDuringExecution:
                    nodeSelectorTerms:
                    - matchExpressions:
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists  # Node must have control-plane role
              # ===== TOLERATIONS =====
              # Allow pod to run on control plane nodes (they have NoSchedule taint)
              tolerations:
                - key: node-role.kubernetes.io/control-plane
                  operator: Exists
                  effect: NoSchedule
              # ===== NETWORKING AND SECURITY =====
              # Use host network to access etcd on localhost:2379
              hostNetwork: true
              # Use host PID namespace for process visibility
              hostPID: true
              # Restart policy: Only restart on failure
              restartPolicy: OnFailure
              # ===== CONTAINER CONFIGURATION =====
              containers:
                - name: etcd-backup
                  # Use Alpine Linux (lightweight, 5MB base image)
                  image: alpine:3.19
                  imagePullPolicy: IfNotPresent  # Use cached image if available
                  command: ["/bin/sh"]
                  args: ["/scripts/backup.sh"]  # Run the backup script
                  # ===== ENVIRONMENT VARIABLES =====
                  env:
                    # Cluster name (leave empty to auto-detect from kubectl context)
                    - name: CLUSTER_NAME
                      value: ""
                    # Kubeconfig path for kubectl commands
                    - name: KUBECONFIG
                      value: "/etc/kubernetes/admin.conf"
                    # Teams webhook URL for notifications (from secret)
                    # Uncomment below to hardcode instead of using secret:
                    # - name: TEAMS_WEBHOOK_URL
                    #   value: "https://your-tenant.webhook.office.com/webhookb2/YOUR-WEBHOOK-URL"
                    - name: TEAMS_WEBHOOK_URL
                      valueFrom:
                        secretKeyRef:
                          name: teams-webhook  # Secret name
                          key: url             # Key within secret
                  # ===== VOLUME MOUNTS =====
                  volumeMounts:
                    # Mount backup script from ConfigMap
                    - name: backup-script
                      mountPath: /scripts
                    # Mount backup directory from host
                    - name: host-backup-dir
                      mountPath: /opt/backup
                    # Mount etcd certificates (read-only)
                    - name: etcd-certs
                      mountPath: /etc/kubernetes/pki/etcd
                      readOnly: true
                    # Mount Kubernetes config directory (read-only)
                    - name: host-etc-kubernetes
                      mountPath: /host/etc/kubernetes
                      readOnly: true
                    # Mount kubeconfig file (read-only)
                    - name: kubeconfig
                      mountPath: /etc/kubernetes/admin.conf
                      readOnly: true
                  # ===== SECURITY CONTEXT =====
                  securityContext:
                    privileged: true  # Required for host filesystem and etcd access
                  # ===== RESOURCE LIMITS =====
                  resources:
                    requests:
                      cpu: 100m       # Request 0.1 CPU cores
                      memory: 256Mi   # Request 256MB RAM
                    limits:
                      cpu: 500m       # Limit to 0.5 CPU cores
                      memory: 512Mi   # Limit to 512MB RAM
              # ===== VOLUMES =====
              volumes:
                # Volume 1: Backup script from ConfigMap
                - name: backup-script
                  configMap:
                    name: etcd-backup-script
                    defaultMode: 0755  # Make script executable
                # Volume 2: Backup directory on host
                - name: host-backup-dir
                  hostPath:
                    path: /opt/backup
                    type: DirectoryOrCreate  # Create if doesn't exist
                # Volume 3: etcd certificates
                - name: etcd-certs
                  hostPath:
                    path: /etc/kubernetes/pki/etcd
                    type: DirectoryOrCreate
                # Volume 4: Kubernetes config directory
                - name: host-etc-kubernetes
                  hostPath:
                    path: /etc/kubernetes
                    type: DirectoryOrCreate
                # Volume 5: Kubeconfig file
                - name: kubeconfig
                  hostPath:
                    path: /etc/kubernetes/admin.conf
                    type: File
    ---
    # Secret: Microsoft Teams webhook URL for notifications
    apiVersion: v1
    kind: Secret
    metadata:
      name: teams-webhook
      namespace: gt-operators
    type: Opaque
    stringData:
      # Replace with your actual Teams webhook URL
      # To get webhook: Teams Channel ‚Üí Connectors ‚Üí Incoming Webhook
      url: "https://your-teams-webhook-url-here"
---
# Deployment for the operator
apiVersion: apps/v1
kind: Deployment
metadata:
  name: etcd-backup-operator
  namespace: gt-operators
spec:
  replicas: 1
  selector:
    matchLabels:
      app: etcd-backup-operator
  template:
    metadata:
      labels:
        app: etcd-backup-operator
    spec:
      serviceAccountName: etcd-backup-operator
      containers:
      - name: operator
        image: bitnami/kubectl:latest
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash", "-c"]
        args:
        - |
          set -e
          echo "======================================"
          echo "ETCD Backup Operator Starting..."
          echo "======================================"
          
          reconcile() {
            local changed=0
            
            if ! kubectl get namespace gt-operators &>/dev/null; then
              echo "[$(date '+%Y-%m-%d %H:%M:%S')] ‚ö†Ô∏è  Namespace missing! Recreating..."
              kubectl apply -f /manifests/manifest.yaml
              return
            fi
            
            kubectl get cronjob etcd-backup -n gt-operators &>/dev/null || changed=1
            kubectl get configmap etcd-backup-script -n gt-operators &>/dev/null || changed=1
            kubectl get serviceaccount etcd-backup-sa -n gt-operators &>/dev/null || changed=1
            kubectl get clusterrole etcd-backup-role &>/dev/null || changed=1
            kubectl get clusterrolebinding etcd-backup-rolebinding &>/dev/null || changed=1
            kubectl get secret teams-webhook -n gt-operators &>/dev/null || changed=1
            
            if [ $changed -eq 1 ]; then
              echo "[$(date '+%Y-%m-%d %H:%M:%S')] üîÑ Reconciling resources..."
              kubectl apply -f /manifests/manifest.yaml
              echo "[$(date '+%Y-%m-%d %H:%M:%S')] ‚úÖ Reconciled"
            fi
          }
          
          echo "Initial reconciliation..."
          reconcile
          
          LOOP=0
          while true; do
            sleep 30
            LOOP=$((LOOP + 1))
            [ $((LOOP % 10)) -eq 0 ] && echo "[$(date '+%Y-%m-%d %H:%M:%S')] üíì Heartbeat"
            reconcile
          done
        volumeMounts:
        - name: manifest
          mountPath: /manifests
        resources:
          requests:
            cpu: 10m
            memory: 64Mi
          limits:
            cpu: 100m
            memory: 128Mi
      volumes:
      - name: manifest
        configMap:
          name: etcd-backup-manifest
